<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>deployment控制器 | Gridea</title>
<link rel="shortcut icon" href="https://ajie825.github.io/favicon.ico?v=1660297996015">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://ajie825.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="deployment控制器 | Gridea - Atom Feed" href="https://ajie825.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="#Deployment官方文档：
https://kubernetes.io/docs/concepts/workloads/controllers/deployment/

deployment概述
deployment是k8s中最常用的..." />
    <meta name="keywords" content="k8s" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://ajie825.github.io">
  <img class="avatar" src="https://ajie825.github.io/images/avatar.png?v=1660297996015" alt="">
  </a>
  <h1 class="site-title">
    Gridea
  </h1>
  <p class="site-description">
    温故而知新
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              deployment控制器
            </h2>
            <div class="post-info">
              <span>
                2022-07-22
              </span>
              <span>
                18 min read
              </span>
              
                <a href="https://ajie825.github.io/tag/hCwwZMyh3G/" class="post-tag">
                  # k8s
                </a>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <pre><code class="language-bash">#Deployment官方文档：
https://kubernetes.io/docs/concepts/workloads/controllers/deployment/
</code></pre>
<h2 id="deployment概述">deployment概述</h2>
<pre><code class="language-bash">deployment是k8s中最常用的资源对象，为replicaset和pod的创建提供了一种声明式的定义方法，在deployment对象中描述一个期望
的状态，deployment控制器就会按照一定的控制速率把实际状态变成期望状态；
通过定义deployment控制器会创建新的replicaset控制器，通过replicaset创建pod，删除deployment控制器，也会删除deployment
控制器下对应的replicaset控制器和pod资源。

使用deployment而不直接创建replicaset是因为deployment拥有许多replicaset没有的特性，例如滚动升级和回滚。
扩展：声明式定义是指直接修改资源清单yaml文件，然后通过kubectl apply -f 资源清单yaml文件，就可以更改资源。

deployment控制器是建立在rs之上的一个控制器，可以管理多个rs，每次更新镜像版本，都会生成一个新的rs，把旧的rs替换掉，
多个rs同时存在，但是只有一个rs运行。
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://ajie825.github.io/post-images/1658458225288.png" alt="" loading="lazy"></figure>
<pre><code class="language-bash">rs v1控制三个pod，删除一个pod，在rs v2上重新建立一个，依次类推，直到全部都是由rs v2控制，如果rs v2有问题，还可以回滚，
deployment是建立在rs之上的，多个rs组成一个deployment，但是只有一个rs处于活跃状态。
</code></pre>
<h2 id="deployment工作原理">deployment工作原理</h2>
<pre><code class="language-bash">如何管理rs和pod？
deployment可以使用声明式定义，直接在命令行通过纯命令的方式完成对应资源版本内容的修改，也就是通过打补丁的方式进行修改；
deployment能提供滚动式自定义自控制的更新；
对deployment来讲，我们在实现更新时还可以实现控制更新节奏和更新逻辑。
</code></pre>
<pre><code class="language-bash">#什么叫做更新节奏和更新逻辑呢？
比如说deployment控制5个pod副本，pod的期望值是5个，但是升级的时候需要额外多几个pod，那deployment控制器可以控制在5个pod副本
之外还能再增加几个pod副本；比方说能多一个，但是不能少，那么升级的时候就是先增加一个，再删除一个，增加一个删除一个，始终保持pod
副本数是5个；
还有一种情况，最多允许多一个，最少允许少一个，也就是最多6个，最少4个，第一次加一个，删除两个，第二次加两个，删除两个，依次类推，
可以自己控制更新方式，这种滚动更新需要加readinessProbe和livenessProbe探测，确保pod中容器里的应用都正常启动了才删除之前的pod，
这就是我们可以自己控制节奏来控制更新的方法。
</code></pre>
<pre><code class="language-bash">通过deployment对象，你可以轻松的做到以下事情：
1）创建replicaset和pod
2）滚动升级（不停止旧服务的状态下升级）和回滚应用（将应用回滚到之前的版本）
3）平滑的扩容和缩容
4）暂停和继续deployment
</code></pre>
<h2 id="deployment资源清单文件编写技巧">deployment资源清单文件编写技巧</h2>
<pre><code class="language-bash">#查看Deployment资源对象由哪几部分组成
[root@master1 ~]# kubectl explain deployment
KIND:     Deployment
VERSION:  apps/v1

DESCRIPTION:
     Deployment enables declarative updates for Pods and ReplicaSets.

FIELDS:
   apiVersion   &lt;string&gt;   #当前资源使用的api版本，跟apiVersion: apps/v1保持一致
   kind &lt;string&gt;           #资源类型，和kind: Deployment保持一致
   metadata     &lt;Object&gt;   #元数据，包括资源的名称、名称空间、标签
   spec &lt;Object&gt;           #定义副本数、定义标签选择器、定义pod模板等
   status       &lt;Object&gt;   #状态，不可修改
</code></pre>
<pre><code class="language-bash">#查看Deployment下的spec字段
[root@master1 ~]# kubectl explain deployment.spec
KIND:     Deployment
VERSION:  apps/v1
RESOURCE: spec &lt;Object&gt;
DESCRIPTION:
    
FIELDS:
   minReadySeconds      &lt;integer&gt;
   #k8s在等待设置的时间后才进行升级，如果没有设置该值，k8s会假设该容器启动后就提供服务
   paused       &lt;boolean&gt;           #暂停，我们更新的时候创建的pod先暂停，不是立即更新
   progressDeadlineSeconds  &lt;integer&gt;
   #k8s在升级过程中有可能由于各种原因升级被卡住（这个时候还没有明确升级失败），比如在拉取被墙的镜像、权限不够等错误；
   #那么这个时候就需要有deadline，在deadline之内如果还卡着，那么就上报这个情况，这个时候deployment状态被标记为Flase,
   #并且注明原因，但是它不会阻止deployment继续进行卡住后面的操作，完全由用户进行控制。
   replicas     &lt;integer&gt;           #副本数
   revisionHistoryLimit &lt;integer&gt;   #保留的历史版本，默认是10
   selector     &lt;Object&gt; -required- #标签选择器，选择它关联的pod
   strategy     &lt;Object&gt; #更新策略
   template     &lt;Object&gt; -required- #定义pod的模板
</code></pre>
<pre><code class="language-bash">#查看Deployment下的spec.strategy字段
[root@master1 ~]# kubectl explain deploy.spec.strategy
KIND:     Deployment
VERSION:  apps/v1
RESOURCE: strategy &lt;Object&gt;
DESCRIPTION:

FIELDS:
   rollingUpdate        &lt;Object&gt;
     
   type &lt;string&gt;
     Type of deployment. Can be &quot;Recreate&quot; or &quot;RollingUpdate&quot;. Default is
     RollingUpdate.
#支持两种更新，Recreate和RollingUpdate
#Recreate是重建式更新，删除一个更新一个
#RollingUpdate滚动式更新，也就是pod能多几个，少几个
</code></pre>
<pre><code class="language-bash">#查看Deployment下的spec.strategy.rollingUpdate字段
[root@master1 ~]# kubectl explain deploy.spec.strategy.rollingUpdate
KIND:     Deployment
VERSION:  apps/v1
RESOURCE: rollingUpdate &lt;Object&gt;
DESCRIPTION:

FIELDS:
   maxSurge     &lt;string&gt;
   #我们更新的过程当中最多允许超出的指定目标副本数有几个；
   #它有两种取值方式，第一种直接给定数量，第二种根据百分比，百分比表示原本是5个，最多可以超出20%，那就允许多一个
   maxUnavailable       &lt;string&gt;  #最多允许几个不可用，假设5个副本，最多一个不可用，就表示最少4个可用 
</code></pre>
<h2 id="deployment使用案例">deployment使用案例</h2>
<pre><code class="language-bash">#deployment是一个三级结构，deployment管理replicaset，replicaset管理pod
1）把myapp-blue-v1.tar.gz和myapp-blue-v2.tar.gz上传到node1和node2上，手动解压：
[root@node1 ~]# docker load -i myapp-blue-v1.tar.gz
[root@node1 ~]# docker load -i myapp-blue-v2.tar.gz
[root@node2 ~]# docker load -i myapp-blue-v1.tar.gz
[root@node2 ~]# docker load -i myapp-blue-v2.tar.gz

2）编写资源清单文件
[root@master1 ~]# cat deploy-demo.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-v1
  namespace: default
  labels:
    app: myapp
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
        version: v1
    spec:
      containers:
      - name: myapp
        image: janakiramm/myapp:v1
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80

3）查看资源信息
[root@master1 ~]# kubectl apply -f deploy-demo.yaml
[root@master1 ~]# kubectl get deployments.apps 
NAME       READY   UP-TO-DATE   AVAILABLE   AGE
myapp-v1   2/2     2            2           52s
NAME：      #创建的控制器名字是myapp-v1
READY：     #显示deployment有多少副本数，它遵循ready/desired的模式
UP-TO-DATE：#显示已更新到所需状态的副本数
AVAILABLE： #显示你可以使用多少个应用程序副本
AGE：       #显示应用程序已运行的时间

#查看deployment创建的rs信息
[root@master1 ~]# kubectl get rs
NAME                  DESIRED   CURRENT   READY   AGE
myapp-v1-67fd9fc9c8   2         2         2       6m36s
NAME：      #创建的RS控制器名称，由deployment的名称-随机数组成
DESIRED：   #显示应用程序的所需副本数，这些副本数是在创建时定义的
CURRENT：   #显示当前正在运行多少个副本
READY：     #显示你的用户可以使用多少个应用程序副本
AGE：       #显示应用程序已运行的时间

#查看deployment创建的pod信息
[root@master1 ~]# kubectl get pods -o wide
NAME                        READY   STATUS    RESTARTS   AGE   IP               NODE   
myapp-v1-67fd9fc9c8-96rwt   1/1     Running   0          15m   10.244.104.1     node2  
myapp-v1-67fd9fc9c8-bkfpf   1/1     Running   0          15m   10.244.166.184   node1  
#pod的名字是由RS的名字-随机数组成的
[root@master1 ~]# curl 10.244.104.1
background-color: blue;
[root@master1 ~]# curl 10.244.166.184
background-color: blue;
</code></pre>
<h3 id="资源清单文件详细解读">资源清单文件详细解读</h3>
<pre><code class="language-bash">apiVersion: apps/v1                  #deployment对应的api版本
kind: Deployment                     #创建的资源是deployment
metadata:
  name: myapp-v1                     #deployment的名字
spec:
  replicas: 2                        #deployment管理的pod副本数
  selector:                          #标签选择器
   matchLabels:                      #matchLabels下定义的标签需要跟template.metadata.labels定义的标签一致
    app: myapp
    version: v1
  template:
   metadata:
    labels:
     app: myapp
     version: v1
   spec:                             #定义容器的属性
    containers:  
    - name: myapp
      image: janakiramm/myapp:v1     #容器使用的镜像
      imagePullPolicy: IfNotPresent  #镜像拉取策略
      ports:
      - containerPort: 80            #容器里的应用的端口
</code></pre>
<h2 id="deployment管理pod扩容-缩容-滚动更新-回滚">deployment管理pod：扩容、缩容、滚动更新、回滚</h2>
<h3 id="deployment实现pod扩容">deployment实现pod扩容</h3>
<pre><code class="language-bash">#把pod副本数变成3，修改deploy-demo.yaml，将replicas: 2 修改为replicas: 3
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
#修改之后保存退出，执行
[root@master1 ~]# kubectl apply -f deploy-demo.yaml 
deployment.apps/myapp-v1 configured
[root@master1 ~]# kubectl get deployments.apps 
NAME       READY   UP-TO-DATE   AVAILABLE   AGE
myapp-v1   3/3     3            3           40m
You have new mail in /var/spool/mail/root
[root@master1 ~]# kubectl get rs
NAME                  DESIRED   CURRENT   READY   AGE
myapp-v1-67fd9fc9c8   3         3         3       40m
[root@master1 ~]# kubectl get pod
NAME                        READY   STATUS    RESTARTS   AGE
myapp-v1-67fd9fc9c8-96rwt   1/1     Running   0          40m
myapp-v1-67fd9fc9c8-bkfpf   1/1     Running   0          40m
myapp-v1-67fd9fc9c8-sz95c   1/1     Running   0          34s
#上面可以看到pod副本已经变成3个
</code></pre>
<h3 id="deployment实现pod缩容">deployment实现pod缩容</h3>
<pre><code class="language-bash">#把pod副本数变成2，方法同扩容一致
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
[root@master1 ~]# kubectl apply -f deploy-demo.yaml 
[root@master1 ~]# kubectl get deployments.apps 
NAME       READY   UP-TO-DATE   AVAILABLE   AGE
myapp-v1   2/2     2            2           43m
[root@master1 ~]# kubectl get rs
NAME                  DESIRED   CURRENT   READY   AGE
myapp-v1-67fd9fc9c8   2         2         2       43m
[root@master1 ~]# kubectl get pods
NAME                        READY   STATUS    RESTARTS   AGE
myapp-v1-67fd9fc9c8-96rwt   1/1     Running   0          43m
myapp-v1-67fd9fc9c8-bkfpf   1/1     Running   0          43m
#deployment的扩容、缩容和replicaset的步骤、方法一致
</code></pre>
<h3 id="deployment实现滚动更新">deployment实现滚动更新</h3>
<pre><code class="language-bash">#重建式更新---删除一个更新一个
1）在一个终端窗口执行如下：
[root@master1 ~]# kubectl get pods -l app=myapp -w
NAME                        READY   STATUS    RESTARTS   AGE
myapp-v1-67fd9fc9c8-96rwt   1/1     Running   0          64m
myapp-v1-67fd9fc9c8-bkfpf   1/1     Running   0          64m

2）打开一个新的终端更改镜像版本，按如下操作
[root@master1 ~]# vim deploy-demo.yaml 
#把image: janakiramm/myapp:v1 变成image: janakiramm/myapp:v2
 spec:
      containers:
      - name: myapp
        image: janakiramm/myapp:v2
        imagePullPolicy: IfNotPresent
[root@master1 ~]# kubectl apply -f deploy-demo.yaml 
deployment.apps/myapp-v1 configured

3）再回到刚才执行监测kubectl get pods -l app=myapp -w的那个窗口，可以看到信息如下：
[root@master1 ~]# kubectl get pods -l app=myapp -w
NAME                        READY   STATUS           RESTARTS     AGE
myapp-v1-67fd9fc9c8-96rwt   1/1     Running             0          64m
myapp-v1-67fd9fc9c8-bkfpf   1/1     Running             0          64m
myapp-v1-75fb478d6c-xg757   0/1     Pending             0          0s
myapp-v1-75fb478d6c-xg757   0/1     Pending             0          0s
myapp-v1-75fb478d6c-xg757   0/1     ContainerCreating   0          0s
myapp-v1-75fb478d6c-xg757   0/1     ContainerCreating   0          0s
myapp-v1-75fb478d6c-xg757   1/1     Running             0          1s
myapp-v1-67fd9fc9c8-bkfpf   1/1     Terminating         0          67m
myapp-v1-75fb478d6c-f5br7   0/1     Pending             0          0s
myapp-v1-75fb478d6c-f5br7   0/1     Pending             0          0s
myapp-v1-75fb478d6c-f5br7   0/1     ContainerCreating   0          0s
myapp-v1-67fd9fc9c8-bkfpf   1/1     Terminating         0          67m
myapp-v1-75fb478d6c-f5br7   0/1     ContainerCreating   0          1s
myapp-v1-67fd9fc9c8-bkfpf   0/1     Terminating         0          67m
myapp-v1-75fb478d6c-f5br7   1/1     Running             0          2s
myapp-v1-67fd9fc9c8-96rwt   1/1     Terminating         0          67m
myapp-v1-67fd9fc9c8-96rwt   1/1     Terminating         0          67m
#Pending表示正在进行调度，ContainerCreating表示真正创建一个pod，Running表示允许一个pod，Running起来一个pod之后再
#Terminating（停掉）一个pod，以此类推，直到所有pod完成滚动升级。

4）在另一个窗口执行
[root@master1 ~]# kubectl get rs
#显示如下，可以看到rs有两个，上面那个是升级之前的，已经被停掉，但是可以随时可以回滚
NAME                  DESIRED   CURRENT   READY   AGE
myapp-v1-67fd9fc9c8   0         0         0       73m
myapp-v1-75fb478d6c   2         2         2       5m22s
[root@master1 ~]# kubectl get pods -o wide
NAME                        READY   STATUS    RESTARTS   AGE   IP               NODE  
myapp-v1-75fb478d6c-f5br7   1/1     Running   0          52m   10.244.104.2     node2   
myapp-v1-75fb478d6c-xg757   1/1     Running   0          52m   10.244.166.186   node1
[root@master1 ~]# curl 10.244.104.2
background-color: green;
[root@master1 ~]# curl 10.244.166.186
background-color: green;

5）查看myapp-v1这个deployment控制器的历史版本
[root@master1 ~]# kubectl rollout history deployment myapp-v1 
deployment.apps/myapp-v1 
REVISION  CHANGE-CAUSE
1         &lt;none&gt;
2         &lt;none&gt;

6）回滚
[root@master1 ~]# kubectl rollout undo deployment myapp-v1 --to-revision=1
deployment.apps/myapp-v1 rolled backdeployment.apps/myapp-v1 rolled back
[root@master1 ~]# kubectl rollout history deployment myapp-v1             
deployment.apps/myapp-v1 
REVISION  CHANGE-CAUSE
2         &lt;none&gt;
3         &lt;none&gt;
[root@master1 ~]# kubectl get rs
NAME                  DESIRED   CURRENT   READY   AGE
myapp-v1-67fd9fc9c8   2         2         2       135m
myapp-v1-75fb478d6c   0         0         0       68m
[root@master1 ~]# kubectl get pods -o wide
NAME                        READY   STATUS    RESTARTS   AGE     IP               NODE 
myapp-v1-67fd9fc9c8-g8s84   1/1     Running   0          2m41s   10.244.166.187   node1 
myapp-v1-67fd9fc9c8-m9vlj   1/1     Running   0          2m39s   10.244.104.4     node2
[root@master1 ~]# curl 10.244.104.4
background-color: blue;
[root@master1 ~]# curl 10.244.166.187 
background-color: blue;
</code></pre>
<h3 id="自定义滚动更新策略">自定义滚动更新策略</h3>
<pre><code class="language-bash">maxSurge和maxUnavailable用来控制滚动更新的更新策略
1）取值范围
数值：maxSurge [0，副本数]，maxUnavailable [0，副本数]
注意：两者不能同时为0。
比例：
maxSurge：      [0%，100%] 向上取整，比如10个副本，5%的话=0.5个，按计算1个；
maxUnavailable：[0%，100%] 向下取整，比如10个副本，5%的话=0.5个，按计算0个。
注意：两者不能同时为0。
2）建议配置
maxSurge == 1
maxUnavailable == 0
这是我们生产环境提供给用户的默认配置，即 &quot;一上一下，先上后下&quot; 最平滑的原则；
1个新版本pod ready（结合readiness）后，才销毁旧版本pod，此配置适用场景是平滑更新、保证服务平稳，但也有缺点，
就是 &quot;太慢&quot; 了。
总结：
maxSurge：      和期望的副本数比，超过期望副本数量最大比例（或最大值），这个值调的越大，副本更新速度越快。
maxUnavailable：和期望的副本数比，不可用副本数量最大比例（或最大值），这个值越小，越能保证服务稳定，更新越平滑。
</code></pre>
<pre><code class="language-bash">#自定义更新策略
修改更新策略：maxUnavailable=1，maxSurge=1 
[root@master1 ~]# cat deploy-demo.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-v1
  namespace: default
  labels:
    app: myapp
spec:
  replicas: 2
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
        version: v1
    spec:
      containers:
      - name: myapp
        image: janakiramm/myapp:v2
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
或者采用打补丁的方法
[root@master1 ~]# kubectl patch deployment myapp-v1 -p '{&quot;spec&quot;:{&quot;strategy&quot;:{&quot;rollingUpdate&quot;: {&quot;maxSurge&quot;:1,&quot;maxUnavailable&quot;:0}}}}'

#查看myapp-v1这个控制器的详细信息
[root@master1 ~]# kubectl describe deployments.apps myapp-v1 
RollingUpdateStrategy:  0 max unavailable, 1 max surge
#这就是通过控制RollingUpdateStrategy这个字段来设置滚动更新策略的
</code></pre>
<h2 id="deployment资源清单详解">deployment资源清单详解</h2>
<pre><code class="language-bash">apiVersion: apps/v1
kind: Deployment 
metadata:
  name: portal
  namespace: ms 
spec:
  replicas: 1
  selector:
    matchLabels:
      project: ms
      app: portal
  template:
    metadata:
      labels:
        project: ms 
        app: portal
    spec:
      containers:
      - name: portal
        image: portal:v1
        imagePullPolicy: Always
        ports:
          - protocol: TCP
            containerPort: 8080 
        resources:         #资源配额
          limits:          #资源限制，最多可用的cpu和内存
            cpu: 1
            memory: 1Gi
         requests：        #最少需要多少资源才可以运行Pod
            cpu: 0.5
            memory: 1Gi
        readinessProbe:
          tcpSocket:
            port: 8080
          initialDelaySeconds: 60
          periodSeconds: 10
        livenessProbe:
          tcpSocket:
            port: 8080
          initialDelaySeconds: 60
          periodSeconds: 10
</code></pre>
<pre><code class="language-bash">livenessProbe   #存活性探测
用于判断容器是否存活，即pod是否为Running状态，如果livenessProbe探针探测到容器不健康，则kubelet将kill掉容器，并
根据容器的重启策略是否重启，如果一个容器不包含livenessProbe探针，则kubelet认为容器的livenessProbe探针的返回值
永远成功。
tcpSocket: 
  port: 8080             #检测8080端口是否存在
initialDelaySeconds: 60  #Pod启动60s执行第一次检查
periodSeconds: 10        #第一次检查后每隔10s检查一次

readinessProbe   #就绪性探测
有时候应用程序可能暂时无法接受请求，比如pod已经Running了，但是容器内应用程序尚未启动成功，在这种情况下，如果没有
readinessProbe，则k8s认为它可以处理请求了，然而此时，程序还没启动成功是不能接收用户请求的，所以不希望k8s把请求
调度给它，则使用readinessPorbe探针。
readinessProbe探针探测容器是否已准备就绪，如果未准备就绪则k8s不会将流量转发给此pod。
tcpSocket: 
  port: 8080             
initialDelaySeconds: 60  
periodSeconds: 10       

livenessProbe和readinessProbe可以使用相同探测方式，只是对pod的处置方式不同，readinessProbe是将pod的IP：port
从对应的EndPoint列表中删除，而livenessProbe则kill容器并根据pod的重启策略来决定作出对应的措施。
</code></pre>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#deployment%E6%A6%82%E8%BF%B0">deployment概述</a></li>
<li><a href="#deployment%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86">deployment工作原理</a></li>
<li><a href="#deployment%E8%B5%84%E6%BA%90%E6%B8%85%E5%8D%95%E6%96%87%E4%BB%B6%E7%BC%96%E5%86%99%E6%8A%80%E5%B7%A7">deployment资源清单文件编写技巧</a></li>
<li><a href="#deployment%E4%BD%BF%E7%94%A8%E6%A1%88%E4%BE%8B">deployment使用案例</a>
<ul>
<li><a href="#%E8%B5%84%E6%BA%90%E6%B8%85%E5%8D%95%E6%96%87%E4%BB%B6%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB">资源清单文件详细解读</a></li>
</ul>
</li>
<li><a href="#deployment%E7%AE%A1%E7%90%86pod%E6%89%A9%E5%AE%B9-%E7%BC%A9%E5%AE%B9-%E6%BB%9A%E5%8A%A8%E6%9B%B4%E6%96%B0-%E5%9B%9E%E6%BB%9A">deployment管理pod：扩容、缩容、滚动更新、回滚</a>
<ul>
<li><a href="#deployment%E5%AE%9E%E7%8E%B0pod%E6%89%A9%E5%AE%B9">deployment实现pod扩容</a></li>
<li><a href="#deployment%E5%AE%9E%E7%8E%B0pod%E7%BC%A9%E5%AE%B9">deployment实现pod缩容</a></li>
<li><a href="#deployment%E5%AE%9E%E7%8E%B0%E6%BB%9A%E5%8A%A8%E6%9B%B4%E6%96%B0">deployment实现滚动更新</a></li>
<li><a href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E6%BB%9A%E5%8A%A8%E6%9B%B4%E6%96%B0%E7%AD%96%E7%95%A5">自定义滚动更新策略</a></li>
</ul>
</li>
<li><a href="#deployment%E8%B5%84%E6%BA%90%E6%B8%85%E5%8D%95%E8%AF%A6%E8%A7%A3">deployment资源清单详解</a></li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://ajie825.github.io/post/replicaset-kong-zhi-qi/">
              <h3 class="post-title">
                replicaset控制器
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://ajie825.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
