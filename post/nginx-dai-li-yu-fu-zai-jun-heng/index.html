<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>nginx代理与负载均衡 | Gridea</title>
<link rel="shortcut icon" href="https://ajie825.github.io/favicon.ico?v=1660297788946">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://ajie825.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="nginx代理与负载均衡 | Gridea - Atom Feed" href="https://ajie825.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="nginx代理
nginx代理服务常见模式
正向代理：为防火墙内的局域网提供访问Internet途径，常用于公司内部的科学上网。
反向代理：将防火墙后面的服务器提供给Internet用户访问，为后端节点没有公网IP的主机进行代理。



正..." />
    <meta name="keywords" content="nginx" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://ajie825.github.io">
  <img class="avatar" src="https://ajie825.github.io/images/avatar.png?v=1660297788946" alt="">
  </a>
  <h1 class="site-title">
    Gridea
  </h1>
  <p class="site-description">
    温故而知新
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              nginx代理与负载均衡
            </h2>
            <div class="post-info">
              <span>
                2022-08-04
              </span>
              <span>
                11 min read
              </span>
              
                <a href="https://ajie825.github.io/tag/JmbVLnHII/" class="post-tag">
                  # nginx
                </a>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <h2 id="nginx代理">nginx代理</h2>
<h3 id="nginx代理服务常见模式">nginx代理服务常见模式</h3>
<pre><code class="language-bash">正向代理：为防火墙内的局域网提供访问Internet途径，常用于公司内部的科学上网。
反向代理：将防火墙后面的服务器提供给Internet用户访问，为后端节点没有公网IP的主机进行代理。
</code></pre>
<p><img src="https://ajie825.github.io/post-images/1659592948466.png" alt="" loading="lazy"><br>
<img src="https://ajie825.github.io/post-images/1659592959972.png" alt="" loading="lazy"></p>
<h3 id="正向代理与反向代理的区别">正向代理与反向代理的区别</h3>
<pre><code class="language-bash">区别在于形式上服务的&quot;对象&quot;不一样
正向代理代理的对象是客户端，为客户端服务----&gt;PC电脑
反向代理代理的对象是服务端，为服务端服务----&gt;服务器
</code></pre>
<h3 id="nginx代理服务支持的协议">nginx代理服务支持的协议</h3>
<figure data-type="image" tabindex="1"><img src="https://ajie825.github.io/post-images/1659592971389.png" alt="" loading="lazy"></figure>
<h3 id="反向代理模式与nginx代理模块">反向代理模式与Nginx代理模块</h3>
<pre><code class="language-bash">反向代理模式                                       nginx配置模块
http\websocket\https\tomcat(java程序)		    ngx_http_proxy_module
fastcgi(PHP程序)				                ngx_http_fastcgi_module
uwsgi(python程序)					            ngx_http_uwsgi_module
grpc(golang程序)					            ngx_http_v2_module
</code></pre>
<h3 id="nginx反向代理配置语法">nginx反向代理配置语法</h3>
<pre><code class="language-bash">1）nginx代理配置语法
Syntax :	proxy_pass URL;
Default:	—
Context:	location, if in location, limit_except
proxy_pass  http://localhost:8000/uri/;
proxy_pass  http://192.168.56.11:8000/uri/;
proxy_pass  http://unix:/tmp/backend.socket:/uri/;
</code></pre>
<pre><code class="language-bash">2）添加发往后端服务器的请求头信息
Syntax :    proxy_set_header field value;
Default:    proxy_set_header Host $proxy_host;
            proxy_set_header Connection close;
Context:    http, server, location
#用户请求的时候host的值是www.bgx.com，那么代理服务会向后端传递请求的还是www.bgx.com
proxy_set_header Host $http_host;
#将$remote_addr的值放进变量X-Real-IP中，$remote_addr的值为客户端的ip
proxy_set_header X-Real-IP $remote_addr;
#客户端通过代理服务访问后端服务，后端服务通过该变量会记录真实客户端地址
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
</code></pre>
<pre><code class="language-bash">3）代理到后端的TCP连接、响应、返回等超时时间
#nginx代理与后端服务器连接超时时间(代理连接超时)
Syntax :    proxy_connect_timeout time;
Default:    proxy_connect_timeout 60s;
Context:    http, server, location
#nginx代理等待后端服务器的响应时间
Syntax :    proxy_read_timeout time;
Default:    proxy_read_timeout 60s;
Context:    http, server, location
#后端服务器数据回传给nginx代理超时时间
Syntax :    proxy_send_timeout time;
Default:    proxy_send_timeout 60s;
Context:    http, server, location
</code></pre>
<pre><code class="language-bash">4）proxy_buffer代理缓冲区
#nignx会把后端返回的内容先放到缓冲区当中，然后再返回给客户端,边收边传, 不是全部接收完再传给客户端
Syntax : proxy_buffering on | off;
Default: proxy_buffering on;
Context: http, server, location
#设置nginx代理保存用户头信息的缓冲区大小
Syntax : proxy_buffer_size size;
Default: proxy_buffer_size 4k|8k;
Context: http, server, location
#proxy_buffers 缓冲区
Syntax : proxy_buffers number size;
Default: proxy_buffers 8 4k|8k;
Context: http, server, location
</code></pre>
<pre><code class="language-bash">5）proxy代理网站常用优化配置如下，将配置写入新文件，调用时使用include引用即可
[root@lb01 ~]# vim /etc/nginx/proxy_params
proxy_set_header Host $http_host;
proxy_set_header X-Real-IP $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
proxy_connect_timeout 30;
proxy_send_timeout 60;
proxy_read_timeout 60;
proxy_buffering on;
proxy_buffer_size 32k;
proxy_buffers 4 128k;
</code></pre>
<pre><code class="language-bash">6）代理配置location时调用，方便后续多个location重复使用
location / {
    proxy_pass http://127.0.0.1:8080;
    include proxy_params;
}
</code></pre>
<h3 id="nginx反向代理场景实践">nginx反向代理场景实践</h3>
<figure data-type="image" tabindex="2"><img src="https://ajie825.github.io/post-images/1659764310714.jpg" alt="" loading="lazy"></figure>
<pre><code class="language-bash">1）环境准备
角色          外网IP             内网IP                主机名
proxy        10.0.0.5          172.16.1.5             lb01
web01        10.0.0.7          172.16.1.5             web01
</code></pre>
<pre><code class="language-bash">2）配置后端web01站点
[root@web01 conf.d]# cat web.oldboy.com.conf 
server {
        listen 80;
        server_name web.oldboy.com;
        root /web;

        location / {
                index index.php index.html;
        }
}
[root@web01 conf.d]# mkdir /web
[root@web01 conf.d]# echo &quot;Web01.....&quot; &gt; /web/index.html
[root@web01 conf.d]# nginx -t
[root@web01 conf.d]# systemctl restart nginx
</code></pre>
<pre><code class="language-bash">3）配置代理
[root@lb01 ~]# cd /etc/nginx/conf.d/
[root@lb01 conf.d]# cat proxy_web.conf 
server {
        listen 80;
        server_name web.oldboy.com;
        location / {
                proxy_pass http://10.0.0.7:80;
                include proxy_params;
        }
}
#proxy_params根据反向代理配置语法配置即可
[root@lb01 conf.d]# systemctl start nginx
[root@lb01 conf.d]# systemctl enable nginx
</code></pre>
<pre><code class="language-bash">4）配置域名解析
10.0.0.5 web.oldboy.com
</code></pre>
<pre><code class="language-bash">5）浏览器访问web.oldboy.com
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://ajie825.github.io/post-images/1659600222053.png" alt="" loading="lazy"></figure>
<h3 id="nginx代理局限性">nginx代理局限性</h3>
<pre><code class="language-bash">一个location仅能代理一台后端主机
</code></pre>
<pre><code class="language-bash">nginx代理生产常用配置：
location  ~ ^/user {
	proxy_pass http://10.0.0.7;
}
location  ~ ^/pass {
	proxy_pass http://10.0.0.8;
}
location  ~ ^/login {
	proxy_pass http://10.0.0.9;
}	
</code></pre>
<h2 id="nginx负载均衡">nginx负载均衡</h2>
<h3 id="为什么需要使用负载均衡">为什么需要使用负载均衡</h3>
<pre><code class="language-bash">当我们的web服务器直接面向用户，往往要承载大量并发请求，单台服务器难以负荷，使用多台web服务器组成集群，前端使用
nginx负载均衡，将请求分散的打到我们的后端服务器集群中，实现负载的分发，那么会大大提升系统的吞吐率、请求性能、高
容灾。
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://ajie825.github.io/post-images/1659602391854.png" alt="" loading="lazy"></figure>
<h3 id="常用公有云的负载均衡">常用公有云的负载均衡</h3>
<pre><code class="language-bash">SLB                         阿里云负载均衡
QLB                         青云负载均衡
CLB                         腾讯负载均衡
ULB                         ucloud的负载均衡
</code></pre>
<pre><code class="language-bash">往往我们接触的最多的是SLB(Server Load Balance)负载均衡，实现最多的也是SLB，因为SLB它的调度节点和服务节点通常
是在一个地域里面。它在这个小的逻辑地域里面决定了它对部分服务的实时性、响应性是非常好的。
所以当海量用户请求过来以后，它同样是请求调度节点，调度节点将用户的请求转发给后端对应的服务节点，服务节点处理完请
求后再转发给调度节点，调度节点最后响应给用户节点，这样也能实现一个均衡的作用。
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://ajie825.github.io/post-images/1659603180400.png" alt="" loading="lazy"></figure>
<h3 id="负载均衡能实现的应用场景">负载均衡能实现的应用场景</h3>
<pre><code class="language-bash">1）应用场景一：四层负载均衡
所谓四层负载均衡指的是OSI七层模型中的传输层，那么传输层nginx已经能支持TCP/IP的控制，所以只需要对客户端的请求
进行TCP/IP协议的包转发就可以实现负载均衡，那么它的好处是性能非常快、只需要底层进行应用处理，而不需要进行一些
复杂的逻辑。
</code></pre>
<figure data-type="image" tabindex="6"><img src="https://ajie825.github.io/post-images/1659764562320.jpg" alt="" loading="lazy"></figure>
<pre><code class="language-bash">2）应用场景二：七层负载均衡
七层负载均衡它是在应用层，那么它可以完成很多应用方面的协议请求，比如我们说的http应用的负载均衡，它可以实现http
信息的改写、头信息的改写、安全应用规则控制、URL匹配规则控制、以及转发、rewrite等等的规则，所以在应用层的服务里
面，我们可以做的内容就更多，那么nginx则是一个典型的七层负载均衡SLB。
</code></pre>
<figure data-type="image" tabindex="7"><img src="https://ajie825.github.io/post-images/1659604402550.png" alt="" loading="lazy"></figure>
<h3 id="四层负载均衡与七层负载均衡区别">四层负载均衡与七层负载均衡区别</h3>
<pre><code class="language-bash">四层负载均衡数据包在底层就进行了分发，而七层负载均衡数据包则在最顶层进行分发、由此可以看出，七层负载均衡效率没
有四层负载均衡高。
但七层负载均衡更贴近于服务，如http协议就是七层协议，我们可以用nginx作会话保持、URL路径规则匹配、head头改写等
等，这些是四层负载均衡无法实现的。
</code></pre>
<h3 id="nginx负载均衡配置场景">nginx负载均衡配置场景</h3>
<pre><code class="language-bash">nginx要实现负载均衡需要用到proxy_pass代理模块配置
nginx负载均衡与nginx代理不同地方在于，nginx代理仅代理一台服务器，而nginx负载均衡则是将客户端请求代理转发一组
upstream虚拟服务池。
</code></pre>
<figure data-type="image" tabindex="8"><img src="https://ajie825.github.io/post-images/1659605084213.png" alt="" loading="lazy"></figure>
<pre><code class="language-bash">Nginx upstream虚拟配置语法
Syntax :	upstream name { ... }
Default:	  —
Context:  http

#upstream例
upstream backend {
    server backend1.example.com weight=5;
    server backend2.example.com:8080;
    server unix:/tmp/backup3;
    server backup1.example.com:8080 backup;
}
server {
    location / {
	    proxy_pass http://backend;
	}
}
</code></pre>
<pre><code class="language-bash">1）环境规划
角色          外网(NAT)          内网(LAN)              主机名
lb01          10.0.0.5           172.16.1.5            lb01
web01         10.0.0.7           172.16.1.7            web01
web02         10.0.0.8           172.16.1.8            web02
</code></pre>
<pre><code class="language-bash">2）web01服务器上配置ngnix，并创建对应Html文件
[root@web01 conf.d]# cat node.conf 
server {
    listen 80;
    server_name node.oldboy.com;
    location / {
        root /node;
        index index.html;
    }
}
[root@web01 conf.d]# mkdir /node
[root@web01 conf.d]# echo &quot;Web01...&quot; &gt; /node/index.html
[root@web01 conf.d]# systemctl reload nginx
</code></pre>
<pre><code class="language-bash">3）web02服务器上配置nginx，并创建对应html文件
[root@web02 ~]# cd /etc/nginx/conf.d/
[root@web02 conf.d]# cat node.conf 
server {
    listen 80;
    server_name node.oldboy.com;
    location / {
        root /node;
        index index.html;
    }
}
[root@web02 conf.d]# mkdir /node
[root@web02 conf.d]# echo &quot;Web02...&quot; &gt; /node/index.html
[root@web02 conf.d]# systemctl reload nginx
</code></pre>
<pre><code class="language-bash">4）配置nginx负载均衡
[root@lb01 conf.d]# cat node_proxy.conf 
upstream node {
    server 172.16.1.7:80;
    server 172.16.1.8:80;
}
server {
    listen 80;
    server_name node.oldboy.com;

    location / {
        proxy_pass http://node;
        include proxy_params;
    }
}
[root@lb01 conf.d]# systemctl reload nginx
</code></pre>
<pre><code class="language-bash">5）准备nginx负载均衡调度使用的proxy_params
[root@lb01 conf.d]# cat /etc/nginx/proxy_params 
proxy_set_header Host $http_host;
proxy_set_header X-Real-IP $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
proxy_connect_timeout 30;
proxy_send_timeout 60;
proxy_read_timeout 60;
proxy_buffering on;
proxy_buffer_size 32k;
proxy_buffers 4 128k;
</code></pre>
<pre><code class="language-bash">6）重新配置负载均衡，建议将upstream写到http层，或者单独写一个upstream.conf文件----生产建议
[root@lb01 conf.d]# cat upstream.conf 
upstream node {
    server 172.16.1.7:80;
    server 172.16.1.8:80;
}
[root@lb01 conf.d]# cat node_proxy.conf 
server {
    listen 80;
    server_name node.oldboy.com;

    location / {
        proxy_pass http://node;
        include proxy_params;
    }
}
server {
    listen 80;
    server_name blog.oldboy.com;
    location / {
        proxy_pass http://node;
        include proxy_params;
    }
}

server {
    listen 80;
    server_name zh.oldboy.com;
    location / {
        proxy_pass http://node;
        include proxy_params;
    }
}
[root@lb01 conf.d]# nginx -t
[root@lb01 conf.d]# systemctl reload nginx
</code></pre>
<pre><code class="language-bash">7）配置域名解析
10.0.0.5 web.oldboy.com node.oldboy.com
</code></pre>
<pre><code class="language-bash">8）浏览器访问node.oldboy.com，然后不断刷新测试
</code></pre>
<p><img src="https://ajie825.github.io/post-images/1659664303488.png" alt="" loading="lazy"><br>
<img src="https://ajie825.github.io/post-images/1659664311634.png" alt="" loading="lazy"></p>
<pre><code class="language-bash">问题：
使用nginx负载均衡时，如何将后端请求超时的服务器流量平滑的切换到另一台服务器上？
nginx本身是有机制的，如果出现一个节点down掉的时候，nginx会根据你负载均衡的设置，将请求转移到其他的节点上，但是如
果后台服务连接没有down掉，但是返回错误异常码如504、502、500，这个时候需要加一个负载均衡的设置，如下配置：
server {
    listen 80;
    server_name oldboy.com;

    location / {
        proxy_pass http://node;
        proxy_next_upstream error timeout http_500 http_502 http_503 http_504;
    }
}
意思是，当其中一台返回错误码404、502...等错误时，可以分配到下一台服务器继续处理程序，提高平台访问成功率。
</code></pre>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#nginx%E4%BB%A3%E7%90%86">nginx代理</a>
<ul>
<li><a href="#nginx%E4%BB%A3%E7%90%86%E6%9C%8D%E5%8A%A1%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%BC%8F">nginx代理服务常见模式</a></li>
<li><a href="#%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E7%9A%84%E5%8C%BA%E5%88%AB">正向代理与反向代理的区别</a></li>
<li><a href="#nginx%E4%BB%A3%E7%90%86%E6%9C%8D%E5%8A%A1%E6%94%AF%E6%8C%81%E7%9A%84%E5%8D%8F%E8%AE%AE">nginx代理服务支持的协议</a></li>
<li><a href="#%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%E4%B8%8Enginx%E4%BB%A3%E7%90%86%E6%A8%A1%E5%9D%97">反向代理模式与Nginx代理模块</a></li>
<li><a href="#nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE%E8%AF%AD%E6%B3%95">nginx反向代理配置语法</a></li>
<li><a href="#nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E5%9C%BA%E6%99%AF%E5%AE%9E%E8%B7%B5">nginx反向代理场景实践</a></li>
<li><a href="#nginx%E4%BB%A3%E7%90%86%E5%B1%80%E9%99%90%E6%80%A7">nginx代理局限性</a></li>
</ul>
</li>
<li><a href="#nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1">nginx负载均衡</a>
<ul>
<li><a href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E4%BD%BF%E7%94%A8%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1">为什么需要使用负载均衡</a></li>
<li><a href="#%E5%B8%B8%E7%94%A8%E5%85%AC%E6%9C%89%E4%BA%91%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1">常用公有云的负载均衡</a></li>
<li><a href="#%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E8%83%BD%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF">负载均衡能实现的应用场景</a></li>
<li><a href="#%E5%9B%9B%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E4%B8%8E%E4%B8%83%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8C%BA%E5%88%AB">四层负载均衡与七层负载均衡区别</a></li>
<li><a href="#nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E9%85%8D%E7%BD%AE%E5%9C%BA%E6%99%AF">nginx负载均衡配置场景</a></li>
</ul>
</li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://ajie825.github.io/post/lnmp-chai-fen/">
              <h3 class="post-title">
                LNMP-拆分
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://ajie825.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
